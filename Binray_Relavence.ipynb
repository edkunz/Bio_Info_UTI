{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top pathogens predicted for test sample:\n",
      "          Pathogen  Probability  Predicted_Present\n",
      "1     K_pneumoniae          1.0               True\n",
      "0           E_coli          0.5               True\n",
      "3       E_faecalis          0.5               True\n",
      "4  S_saprophyticus          0.5               True\n",
      "2      P_mirabilis          0.0               True\n",
      "5     P_aeruginosa          0.0               True\n",
      "\n",
      "Model Evaluation:\n",
      "E_coli Accuracy: 0.5500\n",
      "K_pneumoniae Accuracy: 0.7000\n",
      "P_mirabilis Accuracy: 0.3500\n",
      "E_faecalis Accuracy: 0.4000\n",
      "S_saprophyticus Accuracy: 0.3000\n",
      "P_aeruginosa Accuracy: 0.5500\n",
      "C_albicans Accuracy: 0.6000\n",
      "Overall Hamming Loss: 0.5071\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv(\"fake_patient_data.csv\")\n",
    "\n",
    "# Data Preprocessing\n",
    "predictors = [\"Age_Range\",\"Diabetic\",\"Catheter\"]\n",
    "data = data.dropna()\n",
    "X = data[predictors]\n",
    "y = data.drop(columns=predictors)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "# Model Training\n",
    "pipeline = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    "    MultiOutputClassifier(DecisionTreeClassifier())\n",
    ")\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "def predict_top_pathogens(features_df, top_n=6):\n",
    "    probabilities = []\n",
    "    for i, estimator in enumerate(model.named_steps['multioutputclassifier'].estimators_):\n",
    "        prob = estimator.predict_proba(model.named_steps['onehotencoder'].transform(features_df))[:, 1]\n",
    "        probabilities.append(prob[0])\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Pathogen': y.columns,\n",
    "        'Probability': probabilities\n",
    "    })\n",
    "\n",
    "    result_df = result_df.sort_values(by='Probability', ascending=False)\n",
    "    y_pred = model.predict(features_df)\n",
    "    binary_predictions = y_pred[0] if len(y_pred.shape) > 1 else y_pred\n",
    "    result_df['Predicted_Present'] = [\n",
    "        binary_predictions[y.columns.get_loc(p)] for p in result_df['Pathogen']\n",
    "    ]\n",
    "    result_df['Predicted_Present'] = 1\n",
    "    result_df['Predicted_Present'] = result_df['Predicted_Present'].astype(bool)\n",
    "    return result_df.head(min(top_n, len(y.columns)))\n",
    "\n",
    "# Hamming loss calculation\n",
    "# A measure that quantifies the fraction of incorrect predictions on a per-label basis across a set of predictions\n",
    "def calculate_hamming_loss(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    incorrect_predictions = 0\n",
    "    total_predictions = y_true.shape[0] * y_true.shape[1]\n",
    "    \n",
    "    for i in range(y_true.shape[0]):\n",
    "        for j in range(y_true.shape[1]):\n",
    "            if y_true[i, j] != y_pred[i, j]:\n",
    "                incorrect_predictions += 1\n",
    "    \n",
    "    return incorrect_predictions / total_predictions\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model():\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    for i, pathogen in enumerate(y):\n",
    "        y_test_pathogen = y_test[pathogen].values\n",
    "        y_pred_pathogen = y_pred[:, i]\n",
    "        \n",
    "\n",
    "        accuracy = accuracy_score(y_test_pathogen, y_pred_pathogen)\n",
    "        print(f\"{pathogen} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    hl = calculate_hamming_loss(y_test, y_pred)\n",
    "    print(f\"Overall Hamming Loss: {hl:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "test_sample = X_test.iloc[[14]]\n",
    "top_pathogens = predict_top_pathogens(test_sample)\n",
    "print(\"Top pathogens predicted for test sample:\")\n",
    "print(top_pathogens)\n",
    "\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ellio\\AppData\\Local\\Temp\\ipykernel_16520\\1911118933.py:22: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  pathogens = pathogens.groupby(lambda x: x.split(\"  \")[-1], axis=1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m pathogens \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mfilter(like\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro - prev organism\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m pathogens \u001b[38;5;241m=\u001b[39m pathogens\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[43mpathogens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train-Test Split\u001b[39;00m\n\u001b[0;32m     27\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ellio\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1363\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[1;32m-> 1363\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1365\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv(\"sampledata.csv\")\n",
    "data['demographics - age'] = pd.cut(data['demographics - age'], bins=[0, 20, 40, 60, 80, 100], labels=['0-20', '21-40', '41-60', '61-80', '81+'])\n",
    "\n",
    "# Data Preprocessing\n",
    "predictors = [\"demographics - age\", \"demographics - is_white\", \"demographics - is_veteran\"]\n",
    "data = data.dropna()\n",
    "X = data[predictors]\n",
    "pathogens = data.filter(like=\"micro - prev organism\", axis=1)\n",
    "# pathogens = pathogens.groupby(lambda x: x.split(\"  \"), axis=1)\n",
    "y = data[pathogens.columns]\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=23)\n",
    "\n",
    "# Model Training\n",
    "pipeline = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown='ignore'),\n",
    "    MultiOutputClassifier(DecisionTreeClassifier())\n",
    ")\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "def predict_top_pathogens(features_df, top_n=6):\n",
    "    probabilities = []\n",
    "    for i, estimator in enumerate(model.named_steps['multioutputclassifier'].estimators_):\n",
    "        prob = estimator.predict_proba(model.named_steps['onehotencoder'].transform(features_df))[:, 1]\n",
    "        probabilities.append(prob[0])\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Pathogen': y.columns,\n",
    "        'Probability': probabilities\n",
    "    })\n",
    "\n",
    "    result_df = result_df.sort_values(by='Probability', ascending=False)\n",
    "    y_pred = model.predict(features_df)\n",
    "    binary_predictions = y_pred[0] if len(y_pred.shape) > 1 else y_pred\n",
    "    result_df['Predicted_Present'] = [\n",
    "        binary_predictions[y.columns.get_loc(p)] for p in result_df['Pathogen']\n",
    "    ]\n",
    "    result_df['Predicted_Present'] = 1\n",
    "    result_df['Predicted_Present'] = result_df['Predicted_Present'].astype(bool)\n",
    "    return result_df.head(min(top_n, len(y.columns)))\n",
    "\n",
    "# Hamming loss calculation\n",
    "# A measure that quantifies the fraction of incorrect predictions on a per-label basis across a set of predictions\n",
    "def calculate_hamming_loss(y_true, y_pred):\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.values\n",
    "\n",
    "    incorrect_predictions = 0\n",
    "    total_predictions = y_true.shape[0] * y_true.shape[1]\n",
    "    \n",
    "    for i in range(y_true.shape[0]):\n",
    "        for j in range(y_true.shape[1]):\n",
    "            if y_true[i, j] != y_pred[i, j]:\n",
    "                incorrect_predictions += 1\n",
    "    \n",
    "    return incorrect_predictions / total_predictions\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model():\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    for i, pathogen in enumerate(y):\n",
    "        y_test_pathogen = y_test[pathogen].values\n",
    "        y_pred_pathogen = y_pred[:, i]\n",
    "        \n",
    "\n",
    "        accuracy = accuracy_score(y_test_pathogen, y_pred_pathogen)\n",
    "        print(f\"{pathogen} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    hl = calculate_hamming_loss(y_test, y_pred)\n",
    "    print(f\"Overall Hamming Loss: {hl:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "test_sample = X_test.iloc[[14]]\n",
    "top_pathogens = predict_top_pathogens(test_sample)\n",
    "print(\"Top pathogens predicted for test sample:\")\n",
    "print(top_pathogens)\n",
    "\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
